{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import transforms\n",
        "from torchvision.io import read_image\n",
        "from torchvision.transforms.functional import resize\n",
        "from PIL import Image\n",
        "import os\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "DrqlEH_1ZpVL"
      },
      "id": "DrqlEH_1ZpVL",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Mount Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "wWf4okaJZqYp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6f08abea-721e-465c-ecc1-048a73f32ece"
      },
      "id": "wWf4okaJZqYp",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "009e8fc2",
      "metadata": {
        "id": "009e8fc2"
      },
      "source": [
        "# 1. Build an image segmentation model using pytorch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "133be475",
      "metadata": {
        "id": "133be475"
      },
      "outputs": [],
      "source": [
        "# Custom Dataset class\n",
        "class LungSegmentationDataset(Dataset):\n",
        "    def __init__(self, image_dir, mask_dir, transform=None):\n",
        "        self.image_dir = image_dir\n",
        "        self.mask_dir = mask_dir\n",
        "        self.transform = transform\n",
        "        self.images = os.listdir(image_dir)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.images)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_path = os.path.join(self.image_dir, self.images[idx])\n",
        "        mask_path = os.path.join(self.mask_dir, self.images[idx].replace('.jpg', '_mask.jpg'))\n",
        "        image = Image.open(img_path).convert(\"L\")\n",
        "        mask = Image.open(mask_path).convert(\"L\")\n",
        "\n",
        "        if self.transform is not None:\n",
        "            image = self.transform(image)\n",
        "            mask = self.transform(mask)\n",
        "\n",
        "        return image, mask\n",
        "\n",
        "# Define the U-Net architecture\n",
        "class UNet(nn.Module):\n",
        "    def __init__(self, in_channels=1):\n",
        "        super(UNet, self).__init__()\n",
        "\n",
        "        self.encoder = nn.Sequential(\n",
        "            nn.Conv2d(in_channels, 64, kernel_size=3, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(64, 64, kernel_size=3, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "        )\n",
        "\n",
        "        self.middle = nn.Sequential(\n",
        "            nn.Conv2d(64, 128, kernel_size=3, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(128, 128, kernel_size=3, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "        )\n",
        "\n",
        "        self.decoder = nn.Sequential(\n",
        "            nn.Conv2d(128, 64, kernel_size=3, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(64, 64, kernel_size=3, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.ConvTranspose2d(64, 1, kernel_size=2, stride=2)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x1 = self.encoder(x)\n",
        "        x2 = self.middle(x1)\n",
        "        x3 = self.decoder(x2)\n",
        "\n",
        "        return x3\n",
        "\n",
        "# Compose the transformations\n",
        "transform = transforms.Compose([transforms.ToTensor(), transforms.Resize((256, 256))])\n",
        "\n",
        "# Create datasets and dataloaders\n",
        "train_dataset = LungSegmentationDataset(image_dir='/content/drive/MyDrive/Lung_segmentation/Train/Images',\n",
        "                                        mask_dir='/content/drive/MyDrive/Lung_segmentation/Train/Masks',\n",
        "                                        transform=transform)\n",
        "\n",
        "test_dataset = LungSegmentationDataset(image_dir='/content/drive/MyDrive/Lung_segmentation/Test/Images',\n",
        "                                       mask_dir='/content/drive/MyDrive/Lung_segmentation/Test/Masks',\n",
        "                                       transform=transform)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=4, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=1, shuffle=False)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sample = next(iter(train_loader))\n",
        "image, target = sample\n",
        "\n",
        "# Print the shape of the image and target\n",
        "print(\"Image shape:\", image.shape)\n",
        "print(\"Target shape:\", target.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5RetEIYqnwEL",
        "outputId": "2e5f9d71-9cd0-434b-d061-ebb2b71a30a9"
      },
      "id": "5RetEIYqnwEL",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image shape: torch.Size([4, 1, 256, 256])\n",
            "Target shape: torch.Size([4, 1, 256, 256])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a0c45b84",
      "metadata": {
        "id": "a0c45b84"
      },
      "source": [
        "# 2. Train your model using [lung segmentation datasets](https://github.com/YoushanZhang/Lung_Segmentation)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "50effdac",
      "metadata": {
        "id": "50effdac",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0081e819-89d8-41a5-87cf-92c51589f0be"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/50], Loss: 0.45907673239707947\n",
            "Epoch [2/50], Loss: 0.39476674795150757\n",
            "Epoch [3/50], Loss: 0.4474101960659027\n",
            "Epoch [4/50], Loss: 0.3101367950439453\n",
            "Epoch [5/50], Loss: 0.33101320266723633\n",
            "Epoch [6/50], Loss: 0.3058161735534668\n",
            "Epoch [7/50], Loss: 0.30677154660224915\n",
            "Epoch [8/50], Loss: 0.26566416025161743\n",
            "Epoch [9/50], Loss: 0.2865278124809265\n",
            "Epoch [10/50], Loss: 0.29995888471603394\n",
            "Epoch [11/50], Loss: 0.29523706436157227\n",
            "Epoch [12/50], Loss: 0.23977160453796387\n",
            "Epoch [13/50], Loss: 0.3756483793258667\n",
            "Epoch [14/50], Loss: 0.2244366556406021\n",
            "Epoch [15/50], Loss: 0.27847522497177124\n",
            "Epoch [16/50], Loss: 0.1903161108493805\n",
            "Epoch [17/50], Loss: 0.19471152126789093\n",
            "Epoch [18/50], Loss: 0.1909979283809662\n",
            "Epoch [19/50], Loss: 0.2529662251472473\n",
            "Epoch [20/50], Loss: 0.2113085836172104\n",
            "Epoch [21/50], Loss: 0.21344242990016937\n",
            "Epoch [22/50], Loss: 0.17239150404930115\n",
            "Epoch [23/50], Loss: 0.1683899611234665\n",
            "Epoch [24/50], Loss: 0.1970588117837906\n",
            "Epoch [25/50], Loss: 0.2212207317352295\n",
            "Epoch [26/50], Loss: 0.23286795616149902\n",
            "Epoch [27/50], Loss: 0.22807705402374268\n",
            "Epoch [28/50], Loss: 0.16680403053760529\n",
            "Epoch [29/50], Loss: 0.19895032048225403\n",
            "Epoch [30/50], Loss: 0.14145608246326447\n",
            "Epoch [31/50], Loss: 0.16037717461585999\n",
            "Epoch [32/50], Loss: 0.20803624391555786\n",
            "Epoch [33/50], Loss: 0.16298924386501312\n",
            "Epoch [34/50], Loss: 0.16897444427013397\n",
            "Epoch [35/50], Loss: 0.1556474268436432\n",
            "Epoch [36/50], Loss: 0.15665000677108765\n",
            "Epoch [37/50], Loss: 0.18829740583896637\n",
            "Epoch [38/50], Loss: 0.10078787803649902\n",
            "Epoch [39/50], Loss: 0.10942548513412476\n",
            "Epoch [40/50], Loss: 0.20338641107082367\n",
            "Epoch [41/50], Loss: 0.20895494520664215\n",
            "Epoch [42/50], Loss: 0.14829811453819275\n",
            "Epoch [43/50], Loss: 0.1610717475414276\n",
            "Epoch [44/50], Loss: 0.16007345914840698\n",
            "Epoch [45/50], Loss: 0.1131967157125473\n",
            "Epoch [46/50], Loss: 0.10199978947639465\n",
            "Epoch [47/50], Loss: 0.1864803582429886\n",
            "Epoch [48/50], Loss: 0.14358599483966827\n",
            "Epoch [49/50], Loss: 0.11879492551088333\n",
            "Epoch [50/50], Loss: 0.10046295821666718\n"
          ]
        }
      ],
      "source": [
        "# Initialize the model, loss function, and optimizer\n",
        "model = UNet(in_channels=1)  # Assuming your input images are single-channel\n",
        "criterion = nn.BCEWithLogitsLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.0001)\n",
        "\n",
        "# Training loop\n",
        "num_epochs = 50\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    for batch in train_loader:\n",
        "        inputs, targets = batch\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(inputs)\n",
        "\n",
        "        targets_resized = transforms.Resize((outputs.shape[2], outputs.shape[3]))(targets)\n",
        "\n",
        "        loss = criterion(outputs, targets_resized)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item()}')\n",
        "\n",
        "# Save the trained model\n",
        "torch.save(model.state_dict(), '/content/drive/MyDrive/Lung_segmentation/segmentation_model1.pth')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7f63262f",
      "metadata": {
        "id": "7f63262f"
      },
      "source": [
        "# 3.Evaluate your model using the test images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "687038bb",
      "metadata": {
        "id": "687038bb"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn.functional as F\n",
        "import numpy as np\n",
        "\n",
        "# Load the trained model\n",
        "model = UNet(in_channels=1)\n",
        "model.load_state_dict(torch.load('/content/drive/MyDrive/Lung_segmentation/segmentation_model1.pth'))\n",
        "model.eval()\n",
        "\n",
        "# Evaluate on the test set\n",
        "IoU_values = []\n",
        "Dice_values = []\n",
        "\n",
        "with torch.no_grad():\n",
        "    for batch in test_loader:\n",
        "        inputs, targets = batch\n",
        "        outputs = model(inputs)\n",
        "\n",
        "        # Resize target to match the output size\n",
        "        targets_resized = F.interpolate(targets, size=(outputs.shape[2], outputs.shape[3]), mode='nearest')\n",
        "\n",
        "        # Convert predictions and targets to binary masks\n",
        "        predictions = torch.sigmoid(outputs) > 0.5\n",
        "        targets_binary = targets_resized > 0.5\n",
        "\n",
        "        # Calculate IoU and Dice\n",
        "        intersection = (predictions & targets_binary).sum().item()\n",
        "        union = (predictions | targets_binary).sum().item()\n",
        "        dice = (2.0 * intersection) / (predictions.sum().item() + targets_binary.sum().item())\n",
        "\n",
        "        IoU = intersection / union\n",
        "        IoU_values.append(IoU)\n",
        "        Dice_values.append(dice)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1b5846bc",
      "metadata": {
        "id": "1b5846bc"
      },
      "source": [
        "# 4. Your IoU score should be higher than 0.85"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate the average IoU and Dice\n",
        "average_IoU = np.mean(IoU_values)\n",
        "average_Dice = np.mean(Dice_values)\n",
        "\n",
        "print(f'Average IoU: {average_IoU}')\n",
        "print(f'Average Dice: {average_Dice}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PRz0LRhU4juO",
        "outputId": "e2f3f8e8-0eac-4573-960e-25fa260c4d47"
      },
      "id": "PRz0LRhU4juO",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average IoU: 0.8593397793014086\n",
            "Average Dice: 0.9381251499711834\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "62f12835",
      "metadata": {
        "id": "62f12835"
      },
      "source": [
        "# 5. Write a 2-page report using LaTex and upload your paper to ResearchGate or Arxiv, and put your paper link here.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6f0c16b6",
      "metadata": {
        "id": "6f0c16b6"
      },
      "outputs": [],
      "source": [
        "https://www.researchgate.net/publication/376267327_Lung_Segmentation_from_CT_Scans_using_Neural_Networks\n",
        "https://github.com/Shashi1119/AIM-5001/blob/main/segmentation_model1.pth"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ab6ac291",
      "metadata": {
        "id": "ab6ac291"
      },
      "source": [
        "# 6. Grading rubric\n",
        "\n",
        "(1). Code ------- 20 points (you also need to upload your final model as a pt file, and add paper link)\n",
        "\n",
        "(2). Grammer ---- 20 points\n",
        "\n",
        "(3). Introduction & related work --- 10 points\n",
        "\n",
        "(4). Method  ---- 20 points\n",
        "\n",
        "(5). Results ---- 20 points\n",
        "\n",
        "     > = 0.85 -->10 points\n",
        "     < 0.8  --> 0 points\n",
        "     >= 0.8 & < 0.85  --> 2 point/0.01 higher\n",
        "     \n",
        "\n",
        "(6). Discussion - 10 points"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5299ea7e",
      "metadata": {
        "id": "5299ea7e"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}